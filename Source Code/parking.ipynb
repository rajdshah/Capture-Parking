{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_7QeIZu39sA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e33d7d0-42c0-4c0b-f915-f9b132b3782c"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVEFB1INVj99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "521de099-1272-4401-ab6b-4b2807fc278a"
      },
      "source": [
        "!pip install mrcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mrcnn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/3d/56e05c297a1f464a042b2c47bcd9e5f2d452ce0e5eca3894f7cbdcaee758/mrcnn-0.2.tar.gz (51kB)\n",
            "\r\u001b[K     |██████▍                         | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 20kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 30kB 32.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 40kB 29.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 51kB 31.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 8.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mrcnn\n",
            "  Building wheel for mrcnn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mrcnn: filename=mrcnn-0.2-cp36-none-any.whl size=54932 sha256=e9ef75766fdfa4e29d4134e162b010231a3ece9001c76bdd2944b1332b44532c\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/ed/28/e550ddc897c04c336b923eae4eb35c9aae993d20ce39d9cc40\n",
            "Successfully built mrcnn\n",
            "Installing collected packages: mrcnn\n",
            "Successfully installed mrcnn-0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM9q04Rl7_eP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163c2d65-be79-4214-942d-50088fb1879d"
      },
      "source": [
        "!sudo rm -R short-output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'short-output': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzX44VNlVimr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7da90e-dce4-4f4c-b6c6-0eaa571f62f7"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import mrcnn.config\n",
        "import mrcnn.utils\n",
        "from mrcnn.model import MaskRCNN\n",
        "from pathlib import Path\n",
        "import tensorflow as tf\n",
        "from twilio.rest import Client\n",
        "\n",
        "# Twilio config\n",
        "twilio_account_sid = 'ACfd0be38dfbf0a7b4974a97719ce15301'\n",
        "twilio_auth_token = 'ccda13d270081ca057b2395f1cb6ecb7'\n",
        "twilio_phone_number = 'YOUR_TWILIO_SOURCE_PHONE_NUMBER'\n",
        "destination_phone_number = 'THE_PHONE_NUMBER_TO_TEXT'\n",
        "client = Client(twilio_account_sid, twilio_auth_token)\n",
        "\n",
        "# Configuration that will be used by the Mask-RCNN library\n",
        "class MaskRCNNConfig(mrcnn.config.Config):\n",
        "    NAME = \"coco_pretrained_model_config\"\n",
        "    IMAGES_PER_GPU = 1\n",
        "    GPU_COUNT = 1\n",
        "    NUM_CLASSES = 1 + 80  # COCO dataset has 80 classes + one background class\n",
        "    DETECTION_MIN_CONFIDENCE = 0.6\n",
        "\n",
        "\n",
        "# Filter a list of Mask R-CNN detection results to get only the detected cars / trucks\n",
        "def get_car_boxes(boxes, class_ids):\n",
        "    car_boxes = []\n",
        "\n",
        "    for i, box in enumerate(boxes):\n",
        "        # If the detected object isn't a car / truck, skip it\n",
        "        if class_ids[i] in [3, 8, 6]:\n",
        "            car_boxes.append(box)\n",
        "\n",
        "    return np.array(car_boxes)\n",
        "\n",
        "\n",
        "# Root directory of the project\n",
        "ROOT_DIR = Path(\".\")\n",
        "\n",
        "# Directory to save logs and trained model\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
        "\n",
        "# Local path to trained weights file\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
        "\n",
        "# Download COCO trained weights from Releases if needed\n",
        "if not os.path.exists(COCO_MODEL_PATH):\n",
        "    mrcnn.utils.download_trained_weights(COCO_MODEL_PATH)\n",
        "\n",
        "# Directory of images to run detection on\n",
        "IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n",
        "\n",
        "# Video file or camera to process - set this to 0 to use your webcam instead of a video file\n",
        "VIDEO_SOURCE = \"parking-short.mp4\"\n",
        "\n",
        "# Create a Mask-RCNN model in inference mode\n",
        "model = MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR, config=MaskRCNNConfig())\n",
        "\n",
        "# Load pre-trained model\n",
        "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
        "\n",
        "# Location of parking spaces\n",
        "parked_car_boxes = None\n",
        "\n",
        "# Load the video file we want to run detection on\n",
        "video_capture = cv2.VideoCapture(VIDEO_SOURCE)\n",
        "\n",
        "# How many frames of video we've seen in a row with a parking space open\n",
        "free_space_frames = 0\n",
        "\n",
        "# Have we sent an SMS alert yet?\n",
        "sms_sent = False\n",
        "\n",
        "# Initialize frame number to 0\n",
        "i = 0\n",
        "\n",
        "# Loop over each frame of video\n",
        "while video_capture.isOpened():\n",
        "    success, frame = video_capture.read()\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    # Convert the image from BGR color (which OpenCV uses) to RGB color\n",
        "    rgb_image = frame[:, :, ::-1]\n",
        "\n",
        "    # Run the image through the Mask R-CNN model to get results.\n",
        "    results = model.detect([rgb_image], verbose=0)\n",
        "\n",
        "    # Mask R-CNN assumes we are running detection on multiple images.\n",
        "    # We only passed in one image to detect, so only grab the first result.\n",
        "    r = results[0]\n",
        "\n",
        "\n",
        "    if parked_car_boxes is None:\n",
        "   \n",
        "        parked_car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
        "    else:\n",
        "       \n",
        "        car_boxes = get_car_boxes(r['rois'], r['class_ids'])\n",
        "\n",
        "        \n",
        "        overlaps = mrcnn.utils.compute_overlaps(parked_car_boxes, car_boxes)\n",
        "\n",
        "        free_space = False\n",
        "\n",
        "        # Loop through each known parking space box\n",
        "        for parking_area, overlap_areas in zip(parked_car_boxes, overlaps):\n",
        "\n",
        "            max_IoU_overlap = np.max(overlap_areas)\n",
        "\n",
        "            # Get the top-left and bottom-right coordinates of the parking area\n",
        "            y1, x1, y2, x2 = parking_area\n",
        "\n",
        "           \n",
        "            if max_IoU_overlap < 0.15:\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "                free_space = True\n",
        "            else:\n",
        "                # Parking space is still occupied - draw a red box around it\n",
        "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 1)\n",
        "\n",
        "            # Write the IoU measurement inside the box\n",
        "            font = cv2.FONT_HERSHEY_DUPLEX\n",
        "            cv2.putText(frame, f\"{max_IoU_overlap:0.2}\", (x1 + 6, y2 - 6), font, 0.3, (255, 255, 255))\n",
        "\n",
        "      \n",
        "        if free_space:\n",
        "            free_space_frames += 1\n",
        "        else:\n",
        "            # If no spots are free, reset the count\n",
        "            free_space_frames = 0\n",
        "\n",
        "        # If a space has been free for several frames, we are pretty sure it is really free!\n",
        "        if free_space_frames > 10:\n",
        "            font = cv2.FONT_HERSHEY_DUPLEX\n",
        "            cv2.putText(frame, f\"SPACE AVAILABLE!\", (10, 150), font, 3.0, (0, 255, 0), 2, cv2.FILLED)\n",
        "\n",
        "              # If we haven't sent an SMS yet, sent it!\n",
        "            if not sms_sent:\n",
        "                print(\"SENDING SMS!!!\")\n",
        "                message = client.messages.create(\n",
        "                    body=\"Parking space available!\",\n",
        "                    from_='whatsapp:+14155238886',\n",
        "                    to ='whatsapp:+919820672992'\n",
        "                )\n",
        "                sms_sent = True\n",
        "\n",
        "        # Show the frame of video on the screen\n",
        "        cv2.imwrite('short-output/frame-' + str(i) + '.jpg', frame)\n",
        "        i += 1\n",
        "\n",
        "    # Hit 'q' to quit\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Clean up everything when finished\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading pretrained model to ./mask_rcnn_coco.h5 ...\n",
            "... done downloading pretrained model!\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:399: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:423: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:723: The name tf.sets.set_intersection is deprecated. Please use tf.sets.intersection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:725: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mrcnn/model.py:775: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tf1Sf3v3Rs_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "defbab32-0a6e-46be-9dbd-655f71e82453"
      },
      "source": [
        "!pip3 install twilio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting twilio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/42/1a2855d9a1719e5a5f1b2fe62c56674f218c95c030e13d972fa2efa4b588/twilio-6.47.0.tar.gz (460kB)\n",
            "\r\u001b[K     |▊                               | 10kB 23.7MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20kB 30.6MB/s eta 0:00:01\r\u001b[K     |██▏                             | 30kB 24.1MB/s eta 0:00:01\r\u001b[K     |██▉                             | 40kB 21.8MB/s eta 0:00:01\r\u001b[K     |███▋                            | 51kB 22.2MB/s eta 0:00:01\r\u001b[K     |████▎                           | 61kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 71kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 81kB 17.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 92kB 15.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 102kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 112kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 122kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 133kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 143kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 153kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 163kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 174kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 184kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 194kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 204kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 215kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 225kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 235kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 245kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 256kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 266kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 276kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 286kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 296kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 307kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 317kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 327kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 337kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 348kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 358kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 368kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 378kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 389kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 399kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 409kB 17.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 419kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 430kB 17.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 440kB 17.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 450kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 460kB 17.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from twilio) (1.15.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from twilio) (2018.9)\n",
            "Collecting PyJWT>=1.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from twilio) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->twilio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->twilio) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->twilio) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->twilio) (2.10)\n",
            "Building wheels for collected packages: twilio\n",
            "  Building wheel for twilio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twilio: filename=twilio-6.47.0-py2.py3-none-any.whl size=1217344 sha256=e822d315c81e6fee112afe13764d9854dd62fed78fc6052f8f9bb4d468d47c37\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/03/da/f5b1289ebc34ff99b3f90f2c7d3a3bcf6c838cf7ff51b9017f\n",
            "Successfully built twilio\n",
            "Installing collected packages: PyJWT, twilio\n",
            "Successfully installed PyJWT-1.7.1 twilio-6.47.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v0nOzDoWVhX"
      },
      "source": [
        "!mkdir long-output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "832UnSaIZW6M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e91a06-febd-49bd-c9ef-90a098aa0259"
      },
      "source": [
        "!pip install mrcnn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mrcnn in /usr/local/lib/python3.6/dist-packages (0.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDch__4RhdGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f4ec3f-f56f-47c7-c246-a84831dc6556"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "image_folder = '/content/short-output'\n",
        "video_name = 'video.mp4'\n",
        "#Stitching frames to make a video.\n",
        "images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
        "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
        "\n",
        "for image in images:\n",
        "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d17c95e6a755>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvideo_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'video.mp4'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Stitching frames to make a video.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/short-output'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfmzmS9SJrHE"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "image_folder = '/content/short-output'\n",
        "video_name = 'video.mp4'\n",
        "#Stitching frames to make a video.\n",
        "images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
        "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "video = cv2.VideoWriter(video_name, 0, 1, (width,height))\n",
        "\n",
        "for image in images:\n",
        "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "video.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp5ErijdzM5L"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import glob\n",
        " \n",
        "img_array = []\n",
        "for filename in glob.glob('/content/short-output/*.jpg'):\n",
        "    img = cv2.imread(filename)\n",
        "    height, width, layers = img.shape\n",
        "    size = (width,height)\n",
        "    img_array.append(img)\n",
        " \n",
        " \n",
        "out = cv2.VideoWriter('project.avi',cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
        " \n",
        "for i in range(len(img_array)):\n",
        "    out.write(img_array[i])\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp1DDadghnt4"
      },
      "source": [
        "!mkdir short-output"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}